{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os package\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Import the openai package\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# From the IPython.display package, import display and Markdown\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Use the dotenv package\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Use the CSV Reader Package\n",
    "import csv\n",
    "\n",
    "# Use regular expressions\n",
    "import re\n",
    "\n",
    "# Use subprocess\n",
    "import subprocess\n",
    "\n",
    "load_dotenv()  # This loads the .env file at the root of the project\n",
    "\n",
    "# Set openai.api_key to the OPENAI environment variable\n",
    "client = OpenAI(\n",
    "    api_key = os.getenv(\"OPENAI\")\n",
    ")\n",
    "# print(os.getenv(\"OPENAI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(client, system, user_assistant, openai_model):\n",
    "    \"\"\"\n",
    "    A simple function to handle the mechanics of chatting with ChatGPT\n",
    "    The model is passed in to make it easy to switch models for different tasks\n",
    "    \"\"\"\n",
    "    assert isinstance(system, str), \"`system` should be a string\"\n",
    "    assert isinstance(user_assistant, list), \"`user_assistant` should be a list\"\n",
    "    system_msg = [{\"role\": \"system\", \"content\": system}]\n",
    "    # user_assistant_msgs = [\n",
    "    #     {\"role\": \"assistant\", \"content\": user_assistant[i]} if i % 2 else {\"role\": \"user\", \"content\": user_assistant[i]}\n",
    "    #     for i in range(len(user_assistant))]\n",
    "    user_assistant_msgs = []\n",
    "    for item in user_assistant:\n",
    "        content = item['contents']\n",
    "        msg = {\"role\": \"user\", \"content\": content}\n",
    "        user_assistant_msgs.append(msg)\n",
    "    msgs = system_msg + user_assistant_msgs\n",
    "    response = client.chat.completions.create(model=openai_model, messages=msgs)\n",
    "    status_code = response.choices[0].finish_reason\n",
    "    assert status_code == \"stop\", f\"The status code was {status_code}.\"\n",
    "    # print(f'{response=}')\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file with each row containing a title and a script path.\n",
    "    Returns a list of dictionaries with keys 'title' and 'code_path'.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        data.extend(\n",
    "            {'title': row[0], 'code_path': row[1]}\n",
    "            for row in reader\n",
    "            if len(row) == 2\n",
    "        )\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files_and_update_csv_data(csv_data, repo_root):\n",
    "    \"\"\"\n",
    "    Reads files specified in the data structure and concatenates their contents.\n",
    "    \n",
    "    Parameters:\n",
    "    - csv_data (list of dict): List of dictionaries with 'title' and 'code_path'.\n",
    "    - repo_root (str): Repository root base location.\n",
    "\n",
    "    Returns:\n",
    "    - str: A single string containing all the titles and file contents.\n",
    "    \"\"\"\n",
    "    csv_data_contents = []\n",
    "    for item in csv_data:\n",
    "        full_path = os.path.join(repo_root, item['code_path'])\n",
    "        # print(f'{full_path=}')\n",
    "        full_path = full_path.replace(' ./','/')\n",
    "        try:\n",
    "            with open(full_path, 'r', encoding='utf-8') as file:\n",
    "                contents = file.read()\n",
    "                item['contents'] = contents\n",
    "                csv_data_contents.append(item)\n",
    "        except FileNotFoundError:\n",
    "            concatenated_contents += f\"{item['title']}:\\n<File not found: {full_path}>\\n\\n\\n\"\n",
    "        except Exception as e:\n",
    "            concatenated_contents += f\"{item['title']}:\\n<Error reading file: {e}>\\n\\n\\n\"\n",
    "\n",
    "    return csv_data_contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_repo_root():\n",
    "    return subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).strip().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_markdown_file(item, repo_root, path, response_in):\n",
    "    title = item['title']\n",
    "    file_path = os.path.join(repo_root, path, f\"{title}.md\")\n",
    "\n",
    "    # Extract the content for each block\n",
    "    content = response_in\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(content.strip() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'apb_master_stub', 'code_path': 'rtl/axi/apb_master_stub.sv'}, {'title': 'apb_slave_stub', 'code_path': 'rtl/axi/apb_slave_stub.sv'}, {'title': 'apb_xbar', 'code_path': 'rtl/axi/apb_xbar.sv'}, {'title': 'apb_xbar_thin', 'code_path': 'rtl/axi/apb_xbar_thin.sv'}, {'title': 'axi2apb_convert', 'code_path': 'rtl/axi/axi2apb_convert.sv'}, {'title': 'axi2apb_shim', 'code_path': 'rtl/axi/axi2apb_shim.sv'}, {'title': 'axi_fifo_async', 'code_path': 'rtl/axi/axi_fifo_async.sv'}, {'title': 'axi_fifo_sync', 'code_path': 'rtl/axi/axi_fifo_sync.sv'}, {'title': 'axi_gen_addr', 'code_path': 'rtl/axi/axi_gen_addr.sv'}, {'title': 'axi_master_rd_stub', 'code_path': 'rtl/axi/axi_master_rd_stub.sv'}, {'title': 'axi_master_stub ', 'code_path': 'rtl/axi/axi_master_stub .sv'}, {'title': 'axi_master_wr_stub', 'code_path': 'rtl/axi/axi_master_wr_stub.sv'}, {'title': 'axi_skid_buffer_async', 'code_path': 'rtl/axi/axi_skid_buffer_async.sv'}, {'title': 'axi_skid_buffer', 'code_path': 'rtl/axi/axi_skid_buffer.sv'}, {'title': 'axi_slave_async_stub', 'code_path': 'rtl/axi/axi_slave_async_stub.sv'}, {'title': 'axi_slave_rd_stub', 'code_path': 'rtl/axi/axi_slave_rd_stub.sv'}, {'title': 'axi_slave_stub', 'code_path': 'rtl/axi/axi_slave_stub.sv'}, {'title': 'axi_slave', 'code_path': 'rtl/axi/axi_slave.sv'}, {'title': 'axi_slave_wr_stub', 'code_path': 'rtl/axi/axi_slave_wr_stub.sv'}]\n",
      "/home/sean/github/RTLDesignSherpa\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV File\n",
    "file_path = '/home/sean/github/RTLDesignSherpa/todo_md.csv'\n",
    "csv_data = read_csv_file(file_path)\n",
    "print(csv_data)\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "print(repo_root)\n",
    "csv_data_contents = read_files_and_update_csv_data(csv_data, repo_root)\n",
    "# for item in csv_data_contents:\n",
    "#     print(f'{item[\"title\"]}:{item[\"code_path\"]}\\n{item[\"contents\"]}\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI part 1: saving the individual markdown files\n",
    "openai_model = \"gpt-4-1106-preview\"\n",
    "my_header_prompt = '''\n",
    "In the following text, there will be sections of code that have a header such as:\n",
    "<block>: <path to block>\n",
    "followed by a block of code\n",
    "\n",
    "Please give the Mark Down for the block providing full documentation of the code with knowledge of the other code that is referenced or used as\n",
    "an include file. The Mark Down for each code block should start with a H1 <block> to indicate when a new block begins.\n",
    "It should also include full details of the inputs/outputs and internal functionality along with any command line options needed.\n",
    "At the end of a block, there should be two new lines to provide a visual indicator also.\n",
    "\n",
    "'''\n",
    "for item in csv_data_contents:\n",
    "    prompt = f'{my_header_prompt}{item[\"title\"]}: {item[\"code_path\"]}\\n{item[\"contents\"]}\\n\\n'\n",
    "    # print(prompt)\n",
    "    item['contents'] = prompt\n",
    "    response_fn_test = chat(client, \"You are an expert in python and verilog.\", [item], openai_model)\n",
    "    save_markdown_file(item, repo_root, 'docs/mark_down/AxiRTL/', response_fn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that removes all of the control characters that windows added\n",
    "def remove_escape_characters(text):\n",
    "    # List of Markdown special characters\n",
    "    markdown_chars = ['-', '#', '*', '_', '`', '>', '|', '~', '[', ']', '(', ')']\n",
    "    \n",
    "    # Remove backslash before any Markdown special character\n",
    "    for char in markdown_chars:\n",
    "        text = text.replace(f\"\\\\{char}\", char)\n",
    "    \n",
    "    return text\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "with open(f'{repo_root}/Combined_MD.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "text = remove_escape_characters(text)\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI part 2: Fixing the Combined file for consistency\n",
    "openai_model = \"gpt-4-1106-preview\"\n",
    "# prompt = f'''\n",
    "# The following text is a very long list of markdown files with this demarcation between the blocks\n",
    "# <block>: <path to block>\n",
    "# <markdown contents>\n",
    "\n",
    "# There will also be some index.md and README.md; these shouldn't need much work. Can you leave the contents mostly intact, but do these fixes:\n",
    "# * I am not looking for a summary of the MD files; I need these fixes below.\n",
    "# * within script/val/rtl, respectively can you ensure they are strictly consistent\n",
    "# * across script/val/rtl, respectively can you ensure they are generally consistent\n",
    "# -- for either case if a block has an inconsistency that you cannot fix add a heading at the every end of the ducument called: ## Inconsistencies and list the block and what is inconsistent that you cannot fix.\n",
    "# * In many blocks they say they are part of a bigger whole. Can you use the index.md for rtl/scripts to guide you on what is the top block and what are the sub-blocks. Instead of listing that we don't know anything about the other blocks can you use have a hierarchy of links like this:\n",
    "# [<main block>](<main block>.md)\n",
    "# * [<sub-block>](<sub-block>.md)\n",
    "# * etc\n",
    "\n",
    "# {text}\n",
    "# '''\n",
    "prompt = f'''\n",
    "The following text is a very long list of markdown files with this demarcation between the blocks\n",
    "<block>: <path to block>\n",
    "<markdown contents>\n",
    "\n",
    "There will also be some index.md and README.md; these shouldn't need much work. Can you leave the contents mostly intact, but do these fixes:\n",
    "* I am not looking for a summary of the MD files; I need these fixes below.\n",
    "* within script/val/rtl, respectively can you ensure they are strictly consistent\n",
    "* across script/val/rtl, respectively can you ensure they are generally consistent\n",
    "-- for either case if a block has an inconsistency that you cannot fix add a heading at the every end of the ducument called: ## Inconsistencies and list the block and what is inconsistent that you cannot fix.\n",
    "\n",
    "{text}\n",
    "'''\n",
    "item = {'contents':prompt}\n",
    "response_fn_test = chat(client, \"You are an expert in python and verilog.\", [item], openai_model)\n",
    "\n",
    "file_path = f'{repo_root}/mark_down_fix.txt'\n",
    "with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(response_fn_test.strip() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_code = '''\n",
    "`timescale 1ns / 1ps\n",
    "\n",
    "module dataint_ecc_hamming_decode_secded #(\n",
    "    parameter int WIDTH = 4, parameter int DEBUG = 1\n",
    ") (\n",
    "    input  logic                       i_enable,\n",
    "    input  logic [WIDTH+ParityBits:0]  i_hamming_data,\n",
    "    output logic [WIDTH-1:0]           ow_data,\n",
    "    output logic                       ow_error_detected,\n",
    "    output logic                       ow_double_error_detected\n",
    ");\n",
    "    localparam int ParityBits = $clog2(WIDTH + $clog2(WIDTH) + 1);\n",
    "    localparam int TotalWidth = WIDTH + ParityBits + 1;\n",
    "\n",
    "    // local wires\n",
    "    logic [ParityBits:0]   w_syndrome;\n",
    "    logic [TotalWidth-1:0] w_data_with_parity;\n",
    "    logic                  w_overall_parity;\n",
    "\n",
    "    initial begin\n",
    "        $display(\"-------------------------------------------\");\n",
    "        $display(\"Data Width   %d\", WIDTH);\n",
    "        $display(\"Parity Bits  %d\", ParityBits);\n",
    "        $display(\"Total Width  %d\", TotalWidth);\n",
    "        $display(\"-------------------------------------------\");\n",
    "    end\n",
    "\n",
    "    // Function to calculate the bit position for data extraction\n",
    "    function automatic integer bit_position(input integer k);\n",
    "        integer j, pos;\n",
    "        begin\n",
    "            pos = k + 1; // Adjust for the SECDED bit\n",
    "            for (j = 0; j < ParityBits; j = j + 1) begin\n",
    "                if (pos >= (2**j)) pos = pos + 1;\n",
    "            end\n",
    "            bit_position = pos - 1; // Convert to 0-based index\n",
    "            if (DEBUG)\n",
    "                $display(\"Bit position for data bit %d: %d\", k, bit_position);\n",
    "        end\n",
    "    endfunction\n",
    "\n",
    "    // Function to get a bit mask for the bits covered by a given parity bit\n",
    "    function automatic [TotalWidth-1:0] get_covered_bits(input integer parity_bit);\n",
    "        integer k;\n",
    "        begin\n",
    "            get_covered_bits = 0;\n",
    "            for (k = 0; k < TotalWidth; k = k + 1) begin\n",
    "                // Check if the k-th bit position is covered by the parity_bit\n",
    "                if (((k + 1) >> parity_bit) & 1) begin\n",
    "                    get_covered_bits[k] = 1'b1;\n",
    "                end\n",
    "            end\n",
    "            if (DEBUG)\n",
    "                $display(\"Covered bits for parity bit %d: %b\", parity_bit, get_covered_bits);\n",
    "        end\n",
    "    endfunction\n",
    "\n",
    "    // Check parity bits\n",
    "    integer i;\n",
    "    integer bit_index;\n",
    "    logic [TotalWidth-1:0] w_covered_bits;\n",
    "    always_comb begin\n",
    "        if (i_enable) begin\n",
    "            for (i = 0; i < ParityBits; i = i + 1) begin\n",
    "                w_syndrome[i] = 1'b0; // Initialize to 0\n",
    "                w_covered_bits = get_covered_bits(i);\n",
    "                for (bit_index = 0; bit_index < TotalWidth; bit_index = bit_index + 1) begin\n",
    "                    if (w_covered_bits[bit_index]) begin\n",
    "                        w_syndrome[i] = w_syndrome[i] ^ i_hamming_data[bit_index];\n",
    "                    end\n",
    "                end\n",
    "                if (DEBUG)\n",
    "                    $display(\"Syndrome bit %d: %b\", i, w_syndrome[i]);\n",
    "            end\n",
    "        end else begin\n",
    "            w_syndrome = 'b0;\n",
    "        end\n",
    "    end\n",
    "\n",
    "    always_comb begin\n",
    "        if (i_enable) begin\n",
    "            // Check overall parity\n",
    "            w_overall_parity = ^i_hamming_data[TotalWidth-2:0];\n",
    "            if (DEBUG) begin\n",
    "                $display(\"i_hamming_data[TotalWidth-2:0]: %b\", i_hamming_data[TotalWidth-2:0]);\n",
    "                $display(\"Overall parity: %b\", w_overall_parity);\n",
    "            end\n",
    "\n",
    "            // Calculate syndrome for double error detection\n",
    "            w_syndrome[ParityBits] = w_overall_parity ^ i_hamming_data[TotalWidth-1];\n",
    "            if (DEBUG)\n",
    "                $display(\"Syndrome for double error detection: %b\", w_syndrome[ParityBits]);\n",
    "        end else begin\n",
    "            w_overall_parity = 'b0;\n",
    "            w_syndrome = 'b0;\n",
    "        end\n",
    "    end\n",
    "\n",
    "    // Correct the data if there is a single-bit error\n",
    "    integer j;\n",
    "    always_comb begin\n",
    "        if (i_enable) begin\n",
    "            $display(\"w_syndrome: %b\", w_syndrome);\n",
    "            w_data_with_parity = i_hamming_data;\n",
    "            if (w_syndrome != 0 && w_syndrome != {ParityBits{1'b1}}) begin\n",
    "                // Single-bit error detected and corrected\n",
    "                w_data_with_parity[w_syndrome] = ~w_data_with_parity[w_syndrome];\n",
    "                ow_error_detected = 1'b1;\n",
    "                ow_double_error_detected = 1'b0;\n",
    "                $display(\"Single-bit error detected and corrected at position: %d\", w_syndrome);\n",
    "            end else if (w_syndrome == {ParityBits{1'b1}}) begin\n",
    "                // Double-bit error detected\n",
    "                ow_error_detected = 1'b1;\n",
    "                ow_double_error_detected = 1'b1;\n",
    "                $display(\"Double-bit error detected.\");\n",
    "            end else begin\n",
    "                // No error detected\n",
    "                ow_error_detected = 1'b0;\n",
    "                ow_double_error_detected = 1'b0;\n",
    "                $display(\"No error detected.\");\n",
    "            end\n",
    "        end else begin\n",
    "            w_data_with_parity = 'b0;\n",
    "            ow_error_detected = 'b0;\n",
    "            ow_double_error_detected = 'b0;\n",
    "        end\n",
    "    end\n",
    "\n",
    "    // Extract the corrected data\n",
    "    always_comb begin\n",
    "        if (i_enable) begin\n",
    "            for (j = 0; j < WIDTH; j = j + 1) begin\n",
    "                ow_data[j] = w_data_with_parity[bit_position(j)];\n",
    "                if (DEBUG)\n",
    "                    $display(\"Data bit %d extracted from position %d\", j, bit_position(j));\n",
    "            end\n",
    "        end else begin\n",
    "            ow_data = 'b0;\n",
    "        end\n",
    "\n",
    "    end\n",
    "\n",
    "    // synopsys translate_off\n",
    "    initial begin\n",
    "        $dumpfile(\"dump.vcd\");\n",
    "        $dumpvars(0, dataint_ecc_hamming_decode_secded);\n",
    "    end\n",
    "    // synopsys translate_on\n",
    "\n",
    "endmodule : dataint_ecc_hamming_decode_secded\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = \"gpt-4-1106-preview\"\n",
    "repo_root = find_repo_root()\n",
    "prompt = f'''\n",
    "The following text is verilog for a hamming decoder. It has an infinite feedack loop in it. Can you identify a couple of possibilities?\n",
    "\n",
    "{sv_code}\n",
    "'''\n",
    "item = {'contents':prompt}\n",
    "response_fn_test = chat(client, \"You are an expert in c, python and verilog.\", [item], openai_model)\n",
    "\n",
    "print(response_fn_test)\n",
    "\n",
    "# file_path = f'{repo_root}/bch.py'\n",
    "# with open(file_path, 'w', encoding='utf-8') as file:\n",
    "#     file.write(response_fn_test.strip() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_save_md_files(combined_content, repo_root):\n",
    "    # Regular expression pattern to find sections separated by \"Path:\"\n",
    "    pattern = r'Path: [^\\n]*'\n",
    "    paths = re.findall(pattern, combined_content)\n",
    "    contents = re.split(pattern, combined_content)[1:]  # Ignore the first split which is empty\n",
    "\n",
    "    if len(paths) != len(contents):\n",
    "        print(\"Mismatch between number of paths and contents\")\n",
    "        return\n",
    "\n",
    "    for path_line, md_content in zip(paths, contents):\n",
    "        file_path = path_line.replace(\"Path: \", \"\").strip()\n",
    "\n",
    "        if not file_path.startswith(repo_root):\n",
    "            print(f\"Invalid file path: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            old_file_path = f\"{file_path}.OLD.md\"\n",
    "            shutil.move(file_path, old_file_path)\n",
    "\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(md_content.strip() + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_and_save_md_files(text, repo_root)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
