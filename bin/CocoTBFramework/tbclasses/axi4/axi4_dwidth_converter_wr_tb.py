# SPDX-License-Identifier: MIT
# SPDX-FileCopyrightText: 2024-2025 RTL Design Sherpa
#
# Module: AXI4DWidthConverterWriteTB
# Purpose: AXI4 Write Data Width Converter Testbench (WRITE-ONLY)
#
# Documentation: bin/CocoTBFramework/README.md
# Subsystem: framework
#
# Author: RTL Design Sherpa
# Created: 2025-10-18

"""
AXI4 Write Data Width Converter Testbench - WRITE-ONLY

Reusable testbench infrastructure for testing AXI4 WRITE data width conversion.
Uses GAXI BFMs for protocol-agnostic testing of both upsize and downsize modes.

Tests ONLY the write path (AW, W, B channels).
For read path testing, see axi4_dwidth_converter_rd_tb.py.

Architecture:
- Slave side (narrow in upsize, wide in downsize): GAXI Master drives write transactions
- Master side (wide in upsize, narrow in downsize): GAXI Slave responds to writes
- Queue-based verification for write data integrity checking

This is infrastructure only - test intelligence resides in test runner.
"""

import os
import random
import cocotb

# Framework imports
from CocoTBFramework.tbclasses.shared.tbbase import TBBase
from CocoTBFramework.components.shared.memory_model import MemoryModel

# AXI4 components
from CocoTBFramework.components.axi4.axi4_factories import (
    create_axi4_master_wr,
    create_axi4_master_rd,
    create_axi4_slave_wr,
    create_axi4_slave_rd
)


class AXI4DWidthConverterWriteTB(TBBase):
    """
    AXI4 Write Data Width Converter Testbench - Infrastructure Only (WRITE-ONLY)

    Provides reusable testing infrastructure for AXI4 WRITE data width converter.
    Supports both upsize (narrow→wide) and downsize (wide→narrow) write testing.

    Uses GAXI BFMs:
    - Slave side: GAXI Master to drive transactions
    - Master side: GAXI Slave to respond
    - Shared memory model for data integrity verification

    Test intelligence and scenarios reside in val/amba/test_axi4_dwidth_converter.py
    """

    def __init__(self, dut, aclk=None, aresetn=None):
        """
        Initialize AXI4 Data Width Converter Testbench

        Args:
            dut: Device under test (axi4_dwidth_converter)
            aclk: Clock signal (optional, defaults to dut.aclk)
            aresetn: Reset signal (optional, defaults to dut.aresetn)
        """
        super().__init__(dut)

        # Get test parameters from environment
        self.S_AXI_DATA_WIDTH = self.convert_to_int(os.environ.get('S_AXI_DATA_WIDTH', '32'))
        self.M_AXI_DATA_WIDTH = self.convert_to_int(os.environ.get('M_AXI_DATA_WIDTH', '128'))
        self.AXI_ID_WIDTH = self.convert_to_int(os.environ.get('AXI_ID_WIDTH', '8'))
        self.AXI_ADDR_WIDTH = self.convert_to_int(os.environ.get('AXI_ADDR_WIDTH', '32'))
        self.AXI_USER_WIDTH = self.convert_to_int(os.environ.get('AXI_USER_WIDTH', '1'))
        self.TEST_CLK_PERIOD = self.convert_to_int(os.environ.get('TEST_CLK_PERIOD', '10'))
        self.SEED = self.convert_to_int(os.environ.get('SEED', '12345'))
        self.TIMEOUT_CYCLES = self.convert_to_int(os.environ.get('TIMEOUT_CYCLES', '2000'))

        # Calculate derived parameters
        self.WIDTH_RATIO = max(self.S_AXI_DATA_WIDTH, self.M_AXI_DATA_WIDTH) // \
                          min(self.S_AXI_DATA_WIDTH, self.M_AXI_DATA_WIDTH)
        self.UPSIZE = 1 if self.S_AXI_DATA_WIDTH < self.M_AXI_DATA_WIDTH else 0
        self.DOWNSIZE = 1 if self.S_AXI_DATA_WIDTH > self.M_AXI_DATA_WIDTH else 0
        self.S_STRB_WIDTH = self.S_AXI_DATA_WIDTH // 8
        self.M_STRB_WIDTH = self.M_AXI_DATA_WIDTH // 8

        # Initialize random generator
        random.seed(self.SEED)

        # Setup clock and reset signals
        self.aclk = aclk if aclk else dut.aclk
        self.aclk_name = self.aclk._name if hasattr(self.aclk, '_name') else 'aclk'
        self.aresetn = aresetn if aresetn else dut.aresetn

        # Log configuration
        mode_str = "UPSIZE" if self.UPSIZE else "DOWNSIZE"
        msg = '\n'
        msg += '='*80 + "\n"
        msg += f' AXI4 Data Width Converter Test Configuration:\n'
        msg += '-'*80 + "\n"
        msg += f' Mode:              {mode_str}\n'
        msg += f' Slave Data Width:  {self.S_AXI_DATA_WIDTH} bits\n'
        msg += f' Master Data Width: {self.M_AXI_DATA_WIDTH} bits\n'
        msg += f' Width Ratio:       {self.WIDTH_RATIO}:1\n'
        msg += f' ID Width:          {self.AXI_ID_WIDTH}\n'
        msg += f' Addr Width:        {self.AXI_ADDR_WIDTH}\n'
        msg += f' Clock Period:      {self.TEST_CLK_PERIOD} ns\n'
        msg += f' Seed:              {self.SEED}\n'
        msg += '='*80 + "\n"
        self.log.info(msg)

        # No memory model - use direct queue access per framework guidelines
        # Queue-based verification is simpler and more reliable for this test

        # Simple data store to track written data (address -> list of narrow beats)
        self.data_store = {}

        # Captured master-side data (for verification)
        # Need our own capture because AXI4SlaveWrite callbacks consume the _recvQ
        self.captured_aw_packets = []
        self.captured_w_packets = []

        # Initialize AXI4 components (to be created in setup_clocks_and_reset)
        self.slave_write_master = None  # AXI4 Master Write on slave side (drives s_axi_aw*, s_axi_w*, monitors s_axi_b*)
        self.slave_read_master = None   # AXI4 Master Read on slave side (drives s_axi_ar*, monitors s_axi_r*)
        self.master_write_slave = None  # AXI4 Slave Write on master side (monitors m_axi_aw*, m_axi_w*, drives m_axi_b*)
        self.master_read_slave = None   # AXI4 Slave Read on master side (monitors m_axi_ar*, drives m_axi_r*)

        # Statistics tracking
        self.transactions_sent = 0
        self.transactions_received = 0
        self.errors = 0

        self.log.info("AXI4 Data Width Converter TB initialized")

    async def setup_clocks_and_reset(self):
        """
        Complete initialization - starts clocks and performs reset.

        MANDATORY METHOD: Required by TBBase pattern.
        """
        # Start clock
        await self.start_clock(self.aclk_name, freq=self.TEST_CLK_PERIOD, units='ns')

        # Create AXI4 Master Write on slave side (drives s_axi_aw*, s_axi_w*, monitors s_axi_b*)
        try:
            self.slave_write_master = create_axi4_master_wr(
                dut=self.dut,
                clock=self.aclk,
                prefix='s_axi_',
                log=self.log,
                data_width=self.S_AXI_DATA_WIDTH,
                id_width=self.AXI_ID_WIDTH,
                addr_width=self.AXI_ADDR_WIDTH,
                super_debug=True  # Enable super_debug to validate signal connections
            )
            self.log.info("Created AXI4 Master Write on slave side (s_axi_aw*, s_axi_w*, s_axi_b*)")
        except Exception as e:
            self.log.error(f"Failed to create slave-side write master: {e}")
            raise

        # NO READ SUPPORT - Write converter only tests write path

        # Create AXI4 Slave Write on master side (monitors m_axi_aw*, m_axi_w*, drives m_axi_b*)
        # NO MEMORY MODEL - using queue-based verification
        try:
            self.master_write_slave = create_axi4_slave_wr(
                dut=self.dut,
                clock=self.aclk,
                prefix='m_axi_',
                log=self.log,
                data_width=self.M_AXI_DATA_WIDTH,
                id_width=self.AXI_ID_WIDTH,
                addr_width=self.AXI_ADDR_WIDTH,
                super_debug=True  # Enable super_debug to validate signal connections
            )

            # Add our own callbacks to capture data BEFORE AXI4SlaveWrite processes it
            # (AXI4SlaveWrite callbacks consume the _recvQ, so we need to capture first)
            self.master_write_slave['AW'].add_callback(self._capture_aw_callback)
            self.master_write_slave['W'].add_callback(self._capture_w_callback)

            self.log.info("Created AXI4 Slave Write on master side (m_axi_aw*, m_axi_w*, m_axi_b*) - with capture callbacks")
        except Exception as e:
            self.log.error(f"Failed to create master-side write slave: {e}")
            raise

        # NO READ SUPPORT - Write converter only tests write path

        # Reset sequence
        await self.assert_reset()
        await self.wait_clocks(self.aclk_name, 10)
        await self.deassert_reset()
        await self.wait_clocks(self.aclk_name, 5)

        # Enable VCD dumping for debug
        import os
        if os.environ.get('COCOTB_ENABLE_PROFILING', '0') == '1':
            import cocotb
            cocotb.log.info("VCD dumping enabled via COCOTB_ENABLE_PROFILING")

        self.log.info("Clock and reset setup complete")

    async def assert_reset(self):
        """
        Assert reset signal (active-low).

        MANDATORY METHOD: Required by TBBase pattern.
        """
        self.aresetn.value = 0
        self.log.debug("Reset asserted")

    async def deassert_reset(self):
        """
        Deassert reset signal.

        MANDATORY METHOD: Required by TBBase pattern.
        """
        self.aresetn.value = 1
        self.log.debug("Reset deasserted")

    def _capture_aw_callback(self, aw_pkt):
        """Capture AW packets for verification (called BEFORE AXI4SlaveWrite processes them)"""
        # Create a copy with the data we need (packet object may be reused by BFM)
        pkt_copy = type('obj', (object,), {
            'addr': int(getattr(aw_pkt, 'addr', 0)),
            'len': int(getattr(aw_pkt, 'len', 0)),
            'id': int(getattr(aw_pkt, 'id', 0))
        })()
        self.captured_aw_packets.append(pkt_copy)
        self.log.debug(f"Captured AW: addr=0x{pkt_copy.addr:08X}, len={pkt_copy.len}, id={pkt_copy.id}")

    def _capture_w_callback(self, w_pkt):
        """Capture W packets for verification (called BEFORE AXI4SlaveWrite processes them)"""
        # Create a copy with the data we need (packet object may be reused by BFM)
        pkt_copy = type('obj', (object,), {
            'data': int(getattr(w_pkt, 'data', 0)),
            'last': int(getattr(w_pkt, 'last', 0)),
            'strb': int(getattr(w_pkt, 'strb', 0))
        })()
        self.captured_w_packets.append(pkt_copy)
        self.log.debug(f"Captured W #{len(self.captured_w_packets)}: data=0x{pkt_copy.data:X}, last={pkt_copy.last}")

    async def clear_bfm_state(self):
        """Clear BFM internal queues to prevent stale data from affecting subsequent tests."""
        # Clear our capture lists
        self.captured_aw_packets.clear()
        self.captured_w_packets.clear()

        # Clear BFM internal queues
        if hasattr(self.master_write_slave['interface'], 'orphaned_bursts'):
            self.master_write_slave['interface'].orphaned_bursts.clear()
            self.log.debug("Cleared orphaned_bursts")

        # Clear any pending transactions in the AXI4SlaveWrite queues
        if hasattr(self.master_write_slave['interface'], 'pending_writes'):
            self.master_write_slave['interface'].pending_writes.clear()
            self.log.debug("Cleared pending_writes")

        # Wait a few cycles to let any in-flight transactions complete
        await self.wait_clocks(self.aclk_name, 10)
        self.log.info("BFM state cleared")

    def generate_traceable_data(self, txn_id, burst_len):
        """
        Generate traceable data patterns for waveform debugging.

        For downsize (wide→narrow):
        - Each wide beat is composed of multiple narrow beats
        - Pattern: 0xTT_BB_DD_SS where:
          - TT = transaction ID (0x00-0xFF)
          - BB = beat number within burst (0x00-0xFF)
          - DD = 0xDD (marker byte)
          - SS = sub-beat index (0, 1, 2, 3 for 4:1 ratio)

        For upsize (narrow→wide):
        - Multiple narrow beats combine into wide beat
        - Pattern: 0xTT_BB_DD_NN where NN = narrow beat number

        Args:
            txn_id: Transaction ID (0-255)
            burst_len: Number of beats on SLAVE side

        Returns:
            List of data values for slave side
        """
        data_list = []

        for beat_num in range(burst_len):
            if self.DOWNSIZE:
                # Downsize: Create wide beat with traceable sub-beats
                # For 128→32 (4:1), create 128-bit value with 4 distinct 32-bit lanes
                wide_value = 0
                for sub_beat in range(self.WIDTH_RATIO):
                    # Pattern: TT_BB_DD_SS (transaction, beat, marker, sub-beat)
                    lane_value = ((txn_id & 0xFF) << 24) | \
                                ((beat_num & 0xFF) << 16) | \
                                (0xDD << 8) | \
                                (sub_beat & 0xFF)
                    # Place in appropriate 32-bit lane
                    wide_value |= (lane_value << (sub_beat * self.M_AXI_DATA_WIDTH))
                data_list.append(wide_value)
            else:
                # Upsize: Create narrow beat with traceable pattern
                # Pattern: TT_BB_DD_NN (transaction, beat, marker, narrow beat number)
                narrow_value = ((txn_id & 0xFF) << 24) | \
                               ((beat_num & 0xFF) << 16) | \
                               (0xDD << 8) | \
                               (beat_num & 0xFF)
                data_list.append(narrow_value)

        return data_list

    async def write_transaction(self, addr, data_list, awid=0, awsize=None, awburst=1):
        """
        Perform write transaction - just send data, don't verify here.

        Verification happens by checking data_store in read_transaction.
        The master_write_slave will collect data in its queues automatically.

        Args:
            addr: Start address
            data_list: List of data values (one per beat on SLAVE side)
            awid: Transaction ID
            awsize: Bytes per beat (defaults to slave data width / 8)
            awburst: Burst type (0=FIXED, 1=INCR, 2=WRAP)

        Returns:
            Number of beats written
        """
        if awsize is None:
            awsize = (self.S_AXI_DATA_WIDTH // 8).bit_length() - 1

        # For simple loopback test: just store the data we're writing
        # (DUT doesn't actually write to memory, it just converts width)
        self.data_store[addr] = data_list

        # Send write via slave interface - DUT will convert it
        await self.slave_write_master['interface'].write_transaction(
            address=addr,
            data=data_list,
            id=awid,
            size=awsize,
            burst_type=awburst
        )

        self.transactions_sent += 1
        return len(data_list)

    # NO READ SUPPORT - Write converter only
    # read_transaction() removed - use separate read converter module for reads

    def get_statistics(self):
        """
        Get testbench statistics.

        Returns:
            Dictionary with transaction counts and error counts
        """
        return {
            'transactions_sent': self.transactions_sent,
            'transactions_received': self.transactions_received,
            'errors': self.errors,
            'width_ratio': self.WIDTH_RATIO,
            'mode': 'UPSIZE' if self.UPSIZE else 'DOWNSIZE'
        }

    async def run_basic_test(self):
        """
        Basic smoke test - single write transaction with queue-based verification.

        Uses unique data patterns and collects converted data from master-side
        queues using popleft() when LAST flag occurs (per user request).

        NO READS - DUT is data width converter, not memory!

        Returns:
            True if test passes, False otherwise
        """
        self.log.info("=== Running Basic Smoke Test ===")

        # Write test - use unique data per beat to detect misalignment
        addr = 0x1000

        # Generate unique data pattern based on slave width
        # Each 32-bit word gets a unique replicated byte value
        words_per_beat = self.S_AXI_DATA_WIDTH // 32
        data = []
        word_counter = 1
        for beat in range(2):
            beat_data = 0
            for word_idx in range(words_per_beat):
                byte_value = word_counter & 0xFF
                # Replicate byte across 32-bit word (e.g., 0x01 → 0x01010101)
                word_value = (byte_value << 24) | (byte_value << 16) | (byte_value << 8) | byte_value
                beat_data |= (word_value << (word_idx * 32))
                word_counter += 1
            data.append(beat_data)

        # Clear captured packets before starting
        self.captured_aw_packets.clear()
        self.captured_w_packets.clear()

        # Send write transaction
        await self.write_transaction(addr, data)
        self.log.info(f"Sent {len(data)} beats to address 0x{addr:X}: {[hex(d) for d in data]}")

        # Wait for data to propagate through converter and be captured
        # (Callbacks capture packets as they arrive at master side)
        # Large timeout to handle worst-case backpressure scenarios
        timeout_cycles = 2000  # 2us @ 10ns period
        expected_beats = len(data) * self.WIDTH_RATIO if self.DOWNSIZE else (len(data) + self.WIDTH_RATIO - 1) // self.WIDTH_RATIO

        self.log.info(f"Waiting for converted data (expecting {expected_beats} beats)")

        for cycle in range(timeout_cycles):
            await self.wait_clocks(self.aclk_name, 1)

            captured_count = len(self.captured_w_packets)

            if cycle % 20 == 0:  # Debug every 20 cycles
                self.log.debug(f"Cycle {cycle}: Captured {captured_count} W beats")

            # Check if we have all expected beats
            if captured_count >= expected_beats:
                # Check for LAST flag on final beat
                if captured_count > 0:
                    last_pkt = self.captured_w_packets[-1]
                    if hasattr(last_pkt, 'last') and int(last_pkt.last) == 1:
                        self.log.info(f"Captured {captured_count} beats from master side (LAST detected)")
                        break

        # Verify captured data
        collected_data = [int(getattr(pkt, 'data', 0)) for pkt in self.captured_w_packets]

        success = (len(collected_data) == expected_beats)
        if success:
            self.log.info(f"✅ Basic test PASSED - collected {len(collected_data)}/{expected_beats} beats")
            self.log.info(f"   Converted data: {[hex(d) for d in collected_data]}")
        else:
            self.log.error(f"❌ Basic test FAILED - collected {len(collected_data)}/{expected_beats} beats")
            if len(collected_data) > 0:
                self.log.error(f"   Collected data: {[hex(d) for d in collected_data]}")
            self.errors += 1

        return success

    async def do_write_and_verify(self, addr, data, debug=False):
        """Helper to write and verify using captured packets (like basic test)."""
        # Clear captured packets
        self.captured_aw_packets.clear()
        self.captured_w_packets.clear()

        if debug:
            self.log.info(f"🔍 Starting write: addr=0x{addr:08X}, beats={len(data)}")

        # Send write transaction (waits for B response)
        await self.write_transaction(addr, data)

        # Calculate expected beats
        expected_beats = len(data) * self.WIDTH_RATIO if self.DOWNSIZE else (len(data) + self.WIDTH_RATIO - 1) // self.WIDTH_RATIO

        if debug:
            self.log.info(f"   B response received at {cocotb.utils.get_sim_time('ns')}ns, captured {len(self.captured_w_packets)}/{expected_beats} packets")

        # Wait for all W beats to be captured by monitor callbacks
        # The master may send beats AFTER B response returns
        # Large timeout to handle worst-case backpressure through skid buffers
        timeout_cycles = 2000  # 2us @ 10ns period

        for cycle in range(timeout_cycles):
            captured_count = len(self.captured_w_packets)

            # Check if we have all expected packets
            if captured_count >= expected_beats:
                if captured_count > 0:
                    last_pkt = self.captured_w_packets[-1]
                    if hasattr(last_pkt, 'last') and int(last_pkt.last) == 1:
                        if debug:
                            self.log.info(f"   ✓ All {expected_beats} packets received at +{cycle} cycles ({cocotb.utils.get_sim_time('ns')}ns)")
                        break
            elif captured_count > expected_beats:
                if debug:
                    self.log.error(f"   ❌ Over-captured: {captured_count}/{expected_beats} packets")
                break

            # Wait and poll again
            await self.wait_clocks(self.aclk_name, 1)

        # Verify
        collected_data = [int(getattr(pkt, 'data', 0)) for pkt in self.captured_w_packets]
        success = (len(collected_data) == expected_beats)

        if not success:
            self.log.error(f"❌ Write FAILED - collected {len(collected_data)}/{expected_beats} beats at {cocotb.utils.get_sim_time('ns')}ns")
            if debug:
                self.log.error(f"   Data captured: {[f'0x{d:X}' for d in collected_data]}")
                # Check what's on the bus right now
                m_wvalid = int(self.dut.m_axi_wvalid.value) if hasattr(self.dut, 'm_axi_wvalid') else -1
                m_wready = int(self.dut.m_axi_wready.value) if hasattr(self.dut, 'm_axi_wready') else -1
                m_wlast = int(self.dut.m_axi_wlast.value) if hasattr(self.dut, 'm_axi_wlast') else -1
                self.log.error(f"   Current bus state: m_axi_wvalid={m_wvalid}, m_axi_wready={m_wready}, m_axi_wlast={m_wlast}")
            self.errors += 1
        elif debug:
            self.log.info(f"   ✅ Verification PASSED")

        return success

    async def verify_write_conversion(self, addr, slave_data_list, timeout_cycles=1000):
        """
        Verify write data conversion using direct queue monitoring.

        Args:
            addr: Write address
            slave_data_list: Data to write on slave side
            timeout_cycles: Maximum cycles to wait

        Returns:
            True if verification passes, False otherwise
        """
        # Record initial queue lengths (don't clear - transactions may already be there)
        initial_aw_count = len(self.master_write_slave['interface'].aw_channel._recvQ)
        initial_w_count = len(self.master_write_slave['interface'].w_channel._recvQ)

        # Initiate write on slave side
        await self.write_transaction(addr, slave_data_list)

        # Calculate expected master-side beats
        if self.UPSIZE:
            # Upsize: Multiple slave beats → Single master beat
            expected_master_beats = (len(slave_data_list) + self.WIDTH_RATIO - 1) // self.WIDTH_RATIO
        else:
            # Downsize: Single slave beat → Multiple master beats
            expected_master_beats = len(slave_data_list) * self.WIDTH_RATIO

        # Calculate expected final queue lengths
        expected_aw_count = initial_aw_count + 1
        expected_w_count = initial_w_count + expected_master_beats

        # Wait for AW transaction on master side
        cycles = 0
        while len(self.master_write_slave['interface'].aw_channel._recvQ) < expected_aw_count and cycles < timeout_cycles:
            await self.wait_clocks(self.aclk_name, 1)
            cycles += 1

        if len(self.master_write_slave['interface'].aw_channel._recvQ) < expected_aw_count:
            actual = len(self.master_write_slave['interface'].aw_channel._recvQ)
            self.log.error(f"❌ Timeout waiting for master AW transaction (expected {expected_aw_count}, got {actual})")
            return False

        # Wait for all W beats on master side
        cycles = 0
        while len(self.master_write_slave['interface'].w_channel._recvQ) < expected_w_count and cycles < timeout_cycles:
            await self.wait_clocks(self.aclk_name, 1)
            cycles += 1

        if len(self.master_write_slave['interface'].w_channel._recvQ) < expected_w_count:
            actual_beats = len(self.master_write_slave['interface'].w_channel._recvQ) - initial_w_count
            self.log.error(f"❌ Expected {expected_master_beats} new master beats, got {actual_beats}")
            return False

        # Get AW packet (the new one at index initial_aw_count)
        aw_pkt = self.master_write_slave['interface'].aw_channel._recvQ[initial_aw_count]
        master_addr = getattr(aw_pkt, 'addr', 0)

        # Verify address
        if master_addr != addr:
            self.log.error(f"❌ Address mismatch: Expected 0x{addr:X}, got 0x{master_addr:X}")
            return False

        # Get W packets (the new ones starting at initial_w_count)
        master_data = []
        for i in range(expected_master_beats):
            w_pkt = self.master_write_slave['interface'].w_channel._recvQ[initial_w_count + i]
            data_value = getattr(w_pkt, 'data', 0)
            master_data.append(data_value)

        self.log.info(f"✅ Write verification passed: {len(slave_data_list)} slave beats → {expected_master_beats} master beats")
        return True

    async def run_medium_test(self):
        """
        Medium test - multiple transactions with different patterns.

        Uses unique non-zero data patterns to detect byte/word swapping.

        Includes:
        - Multiple write/read transaction pairs
        - Different burst lengths (1, 2, 4, 8 beats)
        - Sequential and random addresses

        Returns:
            True if all tests pass, False otherwise
        """
        self.log.info("=== Running Medium Test Suite ===")

        all_success = True
        num_transactions = 10
        words_per_beat = self.S_AXI_DATA_WIDTH // 32

        def generate_unique_data(start_value, num_beats):
            """Generate unique data pattern where each 32-bit word is different."""
            data = []
            word_counter = start_value
            for beat in range(num_beats):
                beat_data = 0
                for word_idx in range(words_per_beat):
                    # Each word gets unique replicated byte value
                    byte_value = (word_counter % 255) + 1  # 1-255, avoid 0
                    # Replicate byte across 32-bit word for visual identification
                    word_value = (byte_value << 24) | (byte_value << 16) | (byte_value << 8) | byte_value
                    beat_data |= (word_value << (word_idx * 32))
                    word_counter += 1
                data.append(beat_data)
            return data

        # Test 1: Sequential write transactions (write-only converter)
        self.log.info("--- Test 1: Sequential Write Transactions ---")
        base_addr = 0x1000

        for i in range(num_transactions):
            addr = base_addr + (i * 0x100)
            # Generate unique data for each transaction
            data = generate_unique_data(i * 10, 2)

            # Write and verify on master side
            self.log.info(f"  Starting transaction {i} at 0x{addr:X}")
            success = await self.do_write_and_verify(addr, data)

            if not success:
                self.log.error(f"  ❌ Transaction {i} at 0x{addr:X} FAILED")
                all_success = False
            else:
                self.log.info(f"  ✅ Transaction {i} at 0x{addr:X} PASSED")

        # Test 2: Different burst lengths
        self.log.info("--- Test 2: Variable Burst Lengths ---")
        addr = 0x2000
        for burst_len in [1, 2, 4, 8]:
            data = generate_unique_data(burst_len * 100, burst_len)

            self.log.info(f"  Testing burst length {burst_len}")
            success = await self.do_write_and_verify(addr, data)

            if not success:
                self.log.error(f"  ❌ Burst length {burst_len} test FAILED")
                all_success = False
            else:
                self.log.info(f"  ✅ Burst length {burst_len} test PASSED")
            addr += 0x100

        # Test 3: Random addresses and unique data
        self.log.info("--- Test 3: Random Address/Data Patterns ---")
        for i in range(5):
            addr = random.randint(0x1000, 0xF000) & 0xFFF0  # Align to 16-byte
            burst_len = random.choice([2, 4])
            data = generate_unique_data(i * 1000, burst_len)

            self.log.info(f"  Random test {i} at 0x{addr:X}, len={burst_len}")
            success = await self.do_write_and_verify(addr, data)

            if not success:
                self.log.error(f"  ❌ Random test at 0x{addr:X} FAILED")
                all_success = False
            else:
                self.log.info(f"  ✅ Random test at 0x{addr:X} PASSED")

        if all_success:
            self.log.info("✅ All Medium tests PASSED")
        else:
            self.log.error("❌ Some Medium tests FAILED")

        return all_success

    async def run_full_test(self):
        """
        Full test suite - comprehensive coverage.

        Includes:
        - All medium test scenarios
        - Longer bursts (16, 32 beats)
        - Stress testing with many transactions
        - Mixed read/write patterns
        - Address boundary conditions

        Returns:
            True if all tests pass, False otherwise
        """
        self.log.info("=== Running Full Test Suite ===")

        all_success = True

        # Test 1: Run medium tests first
        self.log.info("--- Test 1: Medium Test Suite (baseline) ---")
        if not await self.run_medium_test():
            all_success = False

        # Test 2: Long bursts (write-only)
        self.log.info("--- Test 2: Long Burst Transactions ---")
        addr = 0x10000
        for burst_len in [16, 32]:
            data = [random.randint(0, 0xFFFFFFFF) for _ in range(burst_len)]

            self.log.info(f"  Testing {burst_len}-beat burst at 0x{addr:X}")
            success = await self.do_write_and_verify(addr, data)

            if not success:
                self.log.error(f"  ❌ Long burst test ({burst_len} beats) FAILED")
                all_success = False
            else:
                self.log.info(f"  ✅ Long burst test ({burst_len} beats) PASSED")
            addr += 0x1000

        # Test 3: Stress test with many write transactions
        num_stress_txns = 20  # Reduced to make debug tractable
        self.log.info(f"--- Test 3: Stress Test ({num_stress_txns} write transactions) ---")

        # CRITICAL: Clear BFM state before stress test to prevent orphaned data from previous tests
        await self.clear_bfm_state()

        base_addr = 0x20000
        failed = 0
        failed_txns = []

        for i in range(num_stress_txns):
            addr = base_addr + (i * 0x80)
            burst_len = random.randint(2, 8)
            # Use traceable data patterns instead of random data for debugging
            data = self.generate_traceable_data(txn_id=i, burst_len=burst_len)

            # Enable debug to see what's happening
            debug = True
            success = await self.do_write_and_verify(addr, data, debug=debug)
            if not success:
                failed += 1
                failed_txns.append((i, burst_len, addr))
                self.log.error(f"  Transaction #{i} FAILED: {burst_len} beats at 0x{addr:08X}")

            # Delay between transactions to ensure complete packet capture
            # and let skid buffers drain
            await self.wait_clocks(self.aclk_name, 50)

            if i % 10 == 0:
                self.log.info(f"  Progress: {i}/{num_stress_txns} transactions")

        if failed > 0:
            self.log.error(f"  ❌ Stress test: {failed}/{num_stress_txns} transactions FAILED")
            self.log.error(f"     Failed transactions: {failed_txns}")
            self.errors += failed
            all_success = False
        else:
            self.log.info(f"  ✅ Stress test: All {num_stress_txns} transactions PASSED")

        # Test 4: Multiple writes to same address (write-only)
        self.log.info("--- Test 4: Sequential Writes to Same Address ---")
        addr = 0x40000
        # Write initial data
        initial_data = [0xAAAAAAAA, 0xBBBBBBBB, 0xCCCCCCCC, 0xDDDDDDDD]
        success = await self.do_write_and_verify(addr, initial_data)

        if not success:
            self.log.error(f"  ❌ Initial write FAILED")
            all_success = False

        # Overwrite with modified data
        modified_data = [0x11111111, 0x22222222, 0x33333333, 0x44444444]
        success = await self.do_write_and_verify(addr, modified_data)

        if not success:
            self.log.error(f"  ❌ Modified write FAILED")
            all_success = False
        else:
            self.log.info(f"  ✅ Sequential writes to same address PASSED")

        # Test 5: Address boundary conditions
        self.log.info("--- Test 5: Address Boundary Conditions ---")
        boundary_addrs = [
            0x0000,      # Start of memory
            0xFFF0,      # Near 4KB boundary
            0x10000,     # 64KB boundary
            0xFFFF0,     # Near 1MB boundary
        ]

        for addr in boundary_addrs:
            data = [random.randint(0, 0xFFFFFFFF) for _ in range(4)]
            success = await self.do_write_and_verify(addr, data)

            if not success:
                self.log.error(f"  ❌ Boundary test at 0x{addr:X} FAILED")
                all_success = False
            else:
                self.log.info(f"  ✅ Boundary test at 0x{addr:X} PASSED")

        # Final result
        if all_success:
            self.log.info("✅ All Full tests PASSED")
        else:
            self.log.error("❌ Some Full tests FAILED")

        return all_success
