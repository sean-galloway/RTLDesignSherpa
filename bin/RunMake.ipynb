{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, join, exists\n",
    "import shutil\n",
    "import glob\n",
    "import subprocess\n",
    "import re\n",
    "import json\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# REMatcher is a utility class to make regex's work similar to Perl\n",
    "# NOTE: if there are any changes needed in this function contact Sean.\n",
    "###############################################################################\n",
    "class REMatcher(object):\n",
    "    ''' This is a utility function to help out with matching regex's and\n",
    "        grabbing the matches out in a way that is similar to how perl\n",
    "        does it.\n",
    "    '''\n",
    "    def __init__(self, matchstring: str) -> None:\n",
    "        self.matchstring = matchstring\n",
    "\n",
    "    def match(self, regexp: str) -> bool:\n",
    "        self.rematch = re.match(regexp, self.matchstring,\n",
    "                                re.IGNORECASE |\n",
    "                                re.MULTILINE |\n",
    "                                re.DOTALL\n",
    "                                )\n",
    "        return bool(self.rematch)\n",
    "\n",
    "    def group(self, i: int) -> str:\n",
    "        return \"Error 999\" if self.rematch is None else self.rematch.group(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file_from_dirs(path, json_file_name, repo_root):\n",
    "    test_list = []\n",
    "\n",
    "    for dir_name in next(os.walk(path))[1]:\n",
    "        test_path = os.path.join(path, dir_name)\n",
    "\n",
    "        # Calculate the relative path after the repo root\n",
    "        test_name = os.path.relpath(test_path, repo_root)\n",
    "\n",
    "        test_dict = {\"test\": test_name}\n",
    "        param_dict = {}\n",
    "\n",
    "        # Read the Makefile\n",
    "        with contextlib.suppress(FileNotFoundError):\n",
    "            with open(os.path.join(test_path, \"Makefile\"), \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "                # Parse for COMPILE_ARGS\n",
    "                for line in lines:\n",
    "                    if re.match(r\"^\\s*#\", line):\n",
    "                        continue  # Skip comments\n",
    "\n",
    "                    compile_args_match = re.findall(r'-P\\s*\\$\\(DUT\\)\\.(\\w+)=(\\w+)', line)\n",
    "                    for param, value in compile_args_match:\n",
    "                        param_dict[param] = value\n",
    "\n",
    "                # Parse for SEED\n",
    "                for line in lines:\n",
    "                    if re.match(r\"^\\s*#\", line):\n",
    "                        continue  # Skip comments\n",
    "\n",
    "                    if seed_match := re.search(r'export SEED=(\\w+)', line):\n",
    "                        test_dict[\"seed\"] = seed_match.group(1)\n",
    "\n",
    "        test_dict[\"param\"] = param_dict\n",
    "        test_list.append(test_dict)\n",
    "\n",
    "    # Sort the list of dictionaries by the 'test' key\n",
    "    test_list.sort(key=lambda x: x['test'])\n",
    "\n",
    "    # Create the JSON file\n",
    "    with open(json_file_name, 'w') as f:\n",
    "        json.dump(test_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_dir_name(base_name):\n",
    "    counter = 0\n",
    "    new_name = base_name\n",
    "    while os.path.exists(new_name):\n",
    "        new_name = f'{base_name}.{counter}'\n",
    "        counter += 1\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(output_file):\n",
    "    with open(output_file, 'r') as f:\n",
    "        line_list = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    for line in line_list:\n",
    "        m = REMatcher(line)\n",
    "        if m.match(r'.*TESTS=(\\d+) PASS=(\\d+) FAIL=(\\d+) SKIP=(\\d+).*'):\n",
    "            tests_tot = int(m.group(1))\n",
    "            tests_pass = int(m.group(2))\n",
    "            tests_fail = int(m.group(3))\n",
    "            tests_skip = int(m.group(4))\n",
    "            print(f'found the results line... {tests_tot=} {tests_pass=} {tests_fail=} {tests_skip=}')\n",
    "            return tests_fail <= 0\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_makefile(makefile_path: str, seed: str, params: dict):\n",
    "    new_lines = []\n",
    "    with open(makefile_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if \"COMPILE_ARGS\" in line and \"export SEED\" not in line:\n",
    "                # Remove existing parameters\n",
    "                if not params:\n",
    "                    continue\n",
    "            \n",
    "            if \"export SEED\" in line and seed is not None:\n",
    "                line = f\"export SEED={seed}\\n\"\n",
    "\n",
    "            new_lines.append(line)\n",
    "        \n",
    "    if params:\n",
    "        param_str = \" \".join([f\"-P $(DUT).{k}={v}\" for k, v in params.items()])\n",
    "        new_lines.append(f\"COMPILE_ARGS += {param_str}\\n\")\n",
    "    \n",
    "    with open(makefile_path, 'w') as f:\n",
    "        f.writelines(new_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_make(repo_root: str, test: str, base_test_path: str, path_out: str, env, seed: str, params: dict):\n",
    "    # Build a custom folder name based on the seed and parameters\n",
    "    folder_suffix = f\"seed_{seed}\"\n",
    "    for param, value in params.items():\n",
    "        folder_suffix += f\"_{param}_{value}\"\n",
    "    \n",
    "    # Combine the test name and custom folder suffix\n",
    "    custom_test_folder = f\"{test}_{folder_suffix}\"\n",
    "    \n",
    "    # Update the test path\n",
    "    regression_test_path = os.path.join(path_out, custom_test_folder)\n",
    "\n",
    "    # set up some local variables\n",
    "    my_command = 'make'\n",
    "    rpt = 'results.txt'\n",
    "    output_file = f'{regression_test_path}/{rpt}'\n",
    "\n",
    "    test_path = f'{repo_root}/{base_test_path}'\n",
    "    if os.path.exists(test_path):\n",
    "        shutil.copytree(test_path, regression_test_path)\n",
    "        \n",
    "    pycache = f'{regression_test_path}/__pycache__/'\n",
    "    if os.path.exists(pycache):\n",
    "        shutil.rmtree(pycache)\n",
    "\n",
    "    os.chdir(f'{regression_test_path}')\n",
    "    \n",
    "    # Update Makefile based on the provided seed and params\n",
    "    makefile_path = f'{regression_test_path}/Makefile'\n",
    "    update_makefile(makefile_path, seed, params)\n",
    "\n",
    "    # Execute the command and capture both stdout and stderr\n",
    "    try:\n",
    "        completed_process = subprocess.run('make clean', shell=True, check=True, capture_output=True, text=True)\n",
    "        completed_process = subprocess.run(my_command, env=env, shell=True, check=True, capture_output=True, text=True)\n",
    "        output_text = completed_process.stdout\n",
    "\n",
    "        # Save the output to a file\n",
    "        with open(output_file, 'w') as file:\n",
    "            file.write(output_text)\n",
    "\n",
    "        # print(\"Command executed successfully. Output saved to:\", output_file)\n",
    "        pass_or_fail = process_results(output_file)\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'Error with {test=}')\n",
    "        print(\"Command failed with exit code:\", e.returncode)\n",
    "        print(\"Error message:\", e.stderr)\n",
    "        # Save the output to a file\n",
    "        with open(output_file, 'w') as file:\n",
    "            file.write(e.stderr)\n",
    "        pass_or_fail = False\n",
    "    return pass_or_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_all_files(directory_path):\n",
    "#     for filename in os.listdir(directory_path):\n",
    "#         file_path = os.path.join(directory_path, filename)\n",
    "#         try:\n",
    "#             if os.path.isfile(file_path):\n",
    "#                 os.unlink(file_path)\n",
    "#         except Exception as e:\n",
    "#             print(f'Failed to delete {file_path}. Reason: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo_root='/home/sean/github/RTL_Design_Projects'\n"
     ]
    }
   ],
   "source": [
    "# Save the current directory\n",
    "original_directory = os.getcwd()\n",
    "# get the repo root\n",
    "repo_root = subprocess.check_output(['git', 'rev-parse', '--show-toplevel']).strip().decode('utf-8')\n",
    "print(f'{repo_root=}')\n",
    "env = os.environ.copy()\n",
    "env['REPO_ROOT'] = repo_root\n",
    "config_file = f'{repo_root}/bin/config.json'\n",
    "with open(config_file, 'r') as f:\n",
    "    config_dct = json.load(f)\n",
    "test_list = 'level0'\n",
    "tag = 'l0_run'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_json_file_from_dirs(f\"{repo_root}/val/common_cocotb_only\", f\"{repo_root}/val/testlists/level0.json\", repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sean/github/RTL_Design_Projects/regression/l0_run/cleanall.mk'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_dir = f'{repo_root}/regression/{tag}'\n",
    "regression_dir = get_unique_dir_name(regression_dir)\n",
    "os.mkdir(regression_dir)\n",
    "cleanall = f'{repo_root}/{config_dct[\"make_clean\"]}'\n",
    "shutil.copy(cleanall, regression_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=2 tests_pass=2 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n",
      "found the results line... tests_tot=1 tests_pass=1 tests_fail=0 tests_skip=0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    json_file_path = f\"{repo_root}/{config_dct['test_lists'][test_list]}\"\n",
    "except KeyError:\n",
    "    print(f'Unknown test list {test_list}')\n",
    "    exit(-1)\n",
    "\n",
    "# Read JSON file\n",
    "with open(json_file_path, 'r') as f:\n",
    "    test_list_json = json.load(f)\n",
    "\n",
    "fail_count = 0\n",
    "fail_list = []\n",
    "for test_count, test_entry in enumerate(test_list_json):\n",
    "    test_path = test_entry['test']\n",
    "    test = test_path.split('/')[-1]\n",
    "    if len(test) == 0:\n",
    "        test = test_path.split('/')[-2]\n",
    "\n",
    "    seed = test_entry.get('seed', 1234)   # Default to None if 'seed' is not in dict\n",
    "    params = test_entry.get('param', {})  # Default to empty dict if 'param' is not in dict\n",
    "\n",
    "    pass_or_fail = run_make(repo_root, test, test_path, regression_dir, env, seed, params)\n",
    "    if pass_or_fail is False:\n",
    "        fail_count += 1\n",
    "        fail_list.append(test)\n",
    "\n",
    "# Change back to the original directory\n",
    "os.chdir(original_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " Test Count = 42        Failures = 0\n",
      "======================================================================\n",
      "Failure List:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_str = f'''\n",
    "======================================================================\n",
    " Test Count = {test_count+1}        Failures = {fail_count}\n",
    "======================================================================\n",
    "Failure List:\n",
    "'''\n",
    "for item in fail_list:\n",
    "    report_str += f'    {item}\\n'\n",
    "print(report_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{regression_dir}/report.txt', 'w') as file:\n",
    "    file.write(report_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
